{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtrfWFFyaQaG",
        "outputId": "11b67958-f593-4c82-f604-19ebcd84e0da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import sys\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Initialize the GPT-2 model and tokenizer\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Create a board representation\n",
        "board = {1: \" \", 2: \" \", 3: \" \",\n",
        "         4: \" \", 5: \" \", 6: \" \",\n",
        "         7: \" \", 8: \" \", 9: \" \"}\n",
        "\n",
        "# Function to print the Tic-Tac-Toe board\n",
        "def print_board(board):\n",
        "    print(f\"{board[1]} | {board[2]} | {board[3]}\")\n",
        "    print(\"---------\")\n",
        "    print(f\"{board[4]} | {board[5]} | {board[6]}\")\n",
        "    print(\"---------\")\n",
        "    print(f\"{board[7]} | {board[8]} | {board[9]}\")\n",
        "\n",
        "# Function to check for a win\n",
        "def check_for_win(board, player):\n",
        "    win_conditions = [(1, 2, 3), (4, 5, 6), (7, 8, 9),\n",
        "                      (1, 4, 7), (2, 5, 8), (3, 6, 9),\n",
        "                      (1, 5, 9), (3, 5, 7)]\n",
        "    for condition in win_conditions:\n",
        "        if board[condition[0]] == board[condition[1]] == board[condition[2]] == player:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# Function to get the next move from the GPT-2 model\n",
        "def get_next_move(model, tokenizer, board, current_player):\n",
        "    board_string = board_to_string(board)\n",
        "\n",
        "    # Create the input for the GPT-2 model\n",
        "    encoded_input = tokenizer.encode(board_string, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate a sequence of tokens\n",
        "    output = model.generate(encoded_input, max_length=2, num_return_sequences=1)\n",
        "    move = int(output[0].decode(\"utf-8\").strip()) - 1\n",
        "\n",
        "    if move < 0 or move > 8 or board[move + 1] != \" \":\n",
        "        print(\"Invalid move. Try again.\")\n",
        "        return get_next_move(model, tokenizer, board, current_player)\n",
        "\n",
        "    return move\n",
        "\n",
        "# Function to insert a letter (X or O) into the board\n",
        "def insert_letter(board, move, player):\n",
        "    board[move + 1] = player\n",
        "\n",
        "# Function to convert the board state to a string\n",
        "def board_to_string(board):\n",
        "    return \"\".join(board.values())\n",
        "\n",
        "# Initialize the current player\n",
        "current_player = \"X\"\n",
        "\n",
        "# Loop until the game is over\n",
        "while True:\n",
        "    print_board(board)\n",
        "\n",
        "    if current_player == \"X\":\n",
        "        # Human player's turn\n",
        "        move = int(input(\"Enter your move (1-9): \")) - 1\n",
        "\n",
        "        if move < 0 or move > 8 or board[move + 1] != \" \":\n",
        "            print(\"Invalid move. Try again.\")\n",
        "            continue\n",
        "    else:\n",
        "        # Computer player's turn (GPT-2)\n",
        "        move = get_next_move(model, tokenizer, board, current_player)\n",
        "\n",
        "    insert_letter(board, move, current_player)\n",
        "\n",
        "    if check_for_win(board, current_player):\n",
        "        print_board(board)\n",
        "        print(f\"{current_player} wins!\")\n",
        "        break\n",
        "    elif \" \" not in board.values():\n",
        "        print_board(board)\n",
        "        print(\"It's a draw!\")\n",
        "        break\n",
        "\n",
        "    current_player = \"O\" if current_player == \"X\" else \"X\"\n"
      ],
      "metadata": {
        "id": "etEFiZopa8J2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zAGiBXhea8Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ik0GxyADa8Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-o72YxJZa8Au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J6wM7xq2a74r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}